{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical tips for class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance\n",
    "\n",
    "Class imbalance: the classes are not represented equally in a classification problem\n",
    "\n",
    "Class imbalance is common in:\n",
    "        + Fraud detection\n",
    "        + Rare adverse drug reactions\n",
    "        + Predict gene families (e.g. Kinase, GPCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from collections import OrderedDict\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data set and plot the points on a 2-dimensional grid (note the imbalance of course)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X, y = load_proteomics()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print('positive class ratio', y.sum()/float(y.shape[0]))\n",
    "fig = pca_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stratification matters!\n",
    "\n",
    "A first tactic we can use is stratification when we are applying cross validation: allocate the samples evenly based on sample classes so that the training and test set have a similiar ratio of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "### IMPLEMENT THE KFOLD (cv) VS STRATIFIEDKFOLD (scv) \n",
    "\n",
    "# Examine the positive labels in train and test folds\n",
    "print('KFold not Stratified')\n",
    "for train_idx, test_idx in cv:\n",
    "    print(y[train_idx].sum(), y[test_idx].sum())\n",
    "\n",
    "print('StratifiedKFold')\n",
    "for train_idx, test_idx in scv:\n",
    "    print(y[train_idx].sum(), y[test_idx].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=5, random_state=RNG)\n",
    "for metric in ['f1', 'roc_auc', 'average_precision', 'accuracy', 'precision', 'recall']:\n",
    "    score1 = cross_val_score(clf, X, y, metric, cv=cv).mean()\n",
    "    score2 = cross_val_score(clf, X, y, metric, cv=scv).mean()\n",
    "    print('%s, CV: %.6f, stratified CV: %.6f' % (metric, score1, score2))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such an easy tactic we already see a significant improve, now we are going to look at different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance metrics for binary classification\n",
    "\n",
    "+ ### Accuracy is misleading\n",
    "![Accuracy](https://upload.wikimedia.org/math/8/c/3/8c3f5b1cef3a52644de5056fd2fafee6.png)\n",
    "+ ### Confusion matrix helps break down the predictive performance to different classes\n",
    "![Confusion matrix](http://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)\n",
    "+ ### Bipartition based metrics (Precision, Recall, F1-score) differs depending on the positive class\n",
    "Precision or positive predictive value (PPV) \n",
    "![Precision](https://upload.wikimedia.org/math/6/b/5/6b55614c9bcfa7596145265be222c4c9.png)\n",
    "Recall or true positive rate (TPR) or sensitivity \n",
    "![Recall](https://upload.wikimedia.org/math/8/b/f/8bf211db6603570bbb1926f911097b18.png)\n",
    "F1-score (harmonic mean of Precision and Recall) \n",
    "![F1-score](https://upload.wikimedia.org/math/9/9/1/991d55cc29b4867c88c6c22d438265f9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "First plot the confusion matrix and observe what is going on (tip: check *classification_report* of sklearn for better viewability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Use these indices for training/test set\n",
    "train_idx, test_idx = list(scv)[0]\n",
    "\n",
    "### IMPLEMENT RANDOM FOREST AND GET CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are going to implement and plot the ROC curve, luckily (as always) sklearn has an easy option for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "\n",
    "### CREATE AND PLOT ROC CURVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling to get more balanced data\n",
    "We will implement two simple resampling techniques, first one is down sampling and the second one is up sampling.\n",
    "\n",
    "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png)\n",
    "\n",
    "We will now see the difference in the distributions when we use the different samplers. You need to implement the under and over samplers using the imblearn package. See: http://contrib.scikit-learn.org/imbalanced-learn/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo the effect of resampling\n",
    "# Load synthetic data\n",
    "X, y = load_synthetic_data()\n",
    "# Original\n",
    "fig = pca_plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down-sampling\n",
    "### IMPLEMENT UNDERSAMPLER AND PLOT PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling\n",
    "### IMPLEMENT OVERRSAMPLER AND PLOT PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement Random Forests with either no sampling, up sampling and down sampling to observe the difference in performance.\n",
    "\n",
    "For this part you need to implement either the up sampling and down sampling tree (check the definition of *ResampleForestClassifier* in *resample_forest.py* for valid options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from resample_forest import ResampleForestClassifier\n",
    "\n",
    "rf = ResampleForestClassifier(tree, n_estimators=10, sampling=None, random_state=RNG, verbose=False)\n",
    "\n",
    "### IMPLEMENT UPSAMPLED RF (rf_up)\n",
    "\n",
    "### IMPLEMENT DOWNSAMPLED RF (rf_dn)\n",
    "\n",
    "clfs = [rf, rf_up, rf_dn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating multiple Random Forests we can create boxplots to see the difference in the AUROC corresponding to different folds of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_proteomics()\n",
    "cv = StratifiedKFold(y, n_folds=5)\n",
    "labels = ['no balancing', 'up-sampling', 'down-sampling']\n",
    "clfs = [rf, rf_up, rf_dn]\n",
    "\n",
    "aurocs = OrderedDict()\n",
    "for i in range(len(clfs)):\n",
    "    clf = clfs[i]\n",
    "    aurocs[labels[i]] = cross_val_score(clf, X, y, 'roc_auc', cv=cv)\n",
    "\n",
    "aurocs = pd.DataFrame(aurocs)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.boxplot(data=aurocs, ax=ax)\n",
    "ax.set_ylabel('CV AUROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, up-sampling is not improving the model score, can you think of any reasons why?\n",
    "\n",
    "We will now show why this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and test performance\n",
    "train_scores = np.zeros((3, len(cv)))\n",
    "test_scores = np.zeros((3, len(cv)))\n",
    "\n",
    "for i, clf in enumerate([rf, rf_up, rf_dn]):\n",
    "    for j, (train_idx, test_idx) in enumerate(cv):\n",
    "        clf = clone(clf) \n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        y_probas = clf.predict_proba(X)[:, 1]\n",
    "        \n",
    "        train_auc = metrics.roc_auc_score(y[train_idx], y_probas[train_idx])\n",
    "        test_auc = metrics.roc_auc_score(y[test_idx], y_probas[test_idx])\n",
    "        \n",
    "        train_scores[i, j] = train_auc\n",
    "        test_scores[i, j] = test_auc\n",
    "        \n",
    "x = range(3)\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "test_mean = test_scores.mean(axis=1)\n",
    "test_std = test_scores.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference between training and test performance\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, train_mean, label='train score', color=COLORS10[0])\n",
    "ax.fill_between(x,  train_mean-train_std, train_mean+train_std, color=COLORS10[0], alpha=0.2)\n",
    "ax.plot(x, test_mean, label='test score', color=COLORS10[1])\n",
    "ax.fill_between(x,  test_mean-test_std, test_mean+test_std, color=COLORS10[1], alpha=0.2)\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('AUROC')\n",
    "ax.set_ylim([0.5,1.1])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the above graph, when is it not a good idea to use up-sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "At last, we will show how a weighted loss function can change the classification performance. Easy interpretation is that errors in the under minority class will be weighted higher than their counterparts to combat the imbalance in the errors. \n",
    "\n",
    "We will use an SVM for this, do not forget to set the kernel to 'linear'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create 40 separable points\n",
    "rng = np.random.RandomState(0)\n",
    "n_samples_1 = 1000\n",
    "n_samples_2 = 100\n",
    "X = np.r_[1.5 * rng.randn(n_samples_1, 2),\n",
    "          0.5 * rng.randn(n_samples_2, 2) + [2, 2]]\n",
    "y = [0] * (n_samples_1) + [1] * (n_samples_2)\n",
    "\n",
    "\n",
    "### CREATE REGULAR SVM MODEL HERE\n",
    "\n",
    "# Get the separating hyperplane of unbalanced SVM\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-5, 5)\n",
    "yy = a * xx - clf.intercept_[0] / w[1]\n",
    "\n",
    "\n",
    "### CREATE BALANCED SVM HERE\n",
    "\n",
    "# Get the separating hyperplane of balanced SVM\n",
    "ww = wclf.coef_[0]\n",
    "wa = -ww[0] / ww[1]\n",
    "wyy = wa * xx - wclf.intercept_[0] / ww[1]\n",
    "\n",
    "# Plot hyperplanes and samples\n",
    "h0 = plt.plot(xx, yy, 'k-', label='no weights')\n",
    "h1 = plt.plot(xx, wyy, 'k--', label='balanced weights')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, alpha=0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.axis('tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
